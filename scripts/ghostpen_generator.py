#!/usr/bin/env python3
"""
GhostPen Generator ‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥—É–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å—Ç–æ–≤.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç Prompt Builder –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ –∏ LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏,
–∑–∞—Ç–µ–º –ø—Ä–∏–º–µ–Ω—è–µ—Ç post-processing –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏.
"""

import json
import re
import sys
from pathlib import Path
from typing import Dict, Any, Optional, List

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ —Å–∫—Ä–∏–ø—Ç–∞–º –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.insert(0, str(Path(__file__).parent))
from prompt_builder import PromptBuilder


class PostProcessor:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤."""
    
    def __init__(self):
        self.emoji_pattern = re.compile(
            "["
            "\U0001F600-\U0001F64F"
            "\U0001F300-\U0001F5FF"
            "\U0001F680-\U0001F6FF"
            "\U0001F1E0-\U0001F1FF"
            "\U00002702-\U000027B0"
            "\U000024C2-\U0001F251"
            "]+", flags=re.UNICODE
        )
    
    def process(
        self,
        text: str,
        target_length: int,
        emoji_density: float,
        hashtag_density: float,
        structure_type: str
    ) -> str:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç.
        
        Args:
            text: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            target_length: –¶–µ–ª–µ–≤–∞—è –¥–ª–∏–Ω–∞
            emoji_density: –ü–ª–æ—Ç–Ω–æ—Å—Ç—å —ç–º–æ–¥–∑–∏
            hashtag_density: –ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Ö—ç—à—Ç–µ–≥–æ–≤
            structure_type: –¢–∏–ø —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            
        Returns:
            –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
        text = self._clean_whitespace(text)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –¥–ª–∏–Ω—É
        text = self._adjust_length(text, target_length)
        
        # –£–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä—ã
        text = self._remove_repetitions(text)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º —ç–º–æ–¥–∑–∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        text = self._adjust_emojis(text, emoji_density)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        text = self._adjust_structure(text, structure_type)
        
        return text.strip()
    
    def _clean_whitespace(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã."""
        # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r' +', ' ', text)
        # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        text = re.sub(r'\n{3,}', '\n\n', text)
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫
        text = re.sub(r'\n +', '\n', text)
        return text.strip()
    
    def _adjust_length(self, text: str, target_length: int) -> str:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞."""
        current_length = len(text)
        tolerance = target_length * 0.25  # 25% –¥–æ–ø—É—Å–∫ (—É–≤–µ–ª–∏—á–µ–Ω–æ)
        
        if current_length < target_length - tolerance:
            # –¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π - –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
            return text
        elif current_length > target_length + tolerance:
            # –£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–±—Ä–µ–∑–∞–Ω–∏–µ: –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º, —Å–æ—Ö—Ä–∞–Ω—è—è —Å–º—ã—Å–ª
            sentences = re.split(r'([.!?]+)', text)
            result = ""
            for i in range(0, len(sentences) - 1, 2):
                if i + 1 < len(sentences):
                    candidate = result + sentences[i] + sentences[i + 1]
                    if len(candidate) <= target_length + tolerance:
                        result = candidate
                    else:
                        # –ï—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è
                        break
            
            # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ N —Å–∏–º–≤–æ–ª–æ–≤
            if len(result) < target_length * 0.5:
                # –û–±—Ä–µ–∑–∞–µ–º –ø–æ —Å–ª–æ–≤–∞–º, —á—Ç–æ–±—ã –Ω–µ –æ–±—Ä—ã–≤–∞—Ç—å —Å–ª–æ–≤–æ
                words = text[:target_length + tolerance].split()
                result = ' '.join(words[:-1]) if len(words) > 1 else text[:target_length]
            
            return result if result else text[:target_length]
        
        return text
    
    def _remove_repetitions(self, text: str) -> str:
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –ø–æ–≤—Ç–æ—Ä–æ–≤ —Ñ—Ä–∞–∑."""
        sentences = re.split(r'([.!?]+)', text)
        result = []
        seen_phrases = set()
        
        for i in range(0, len(sentences) - 1, 2):
            if i + 1 < len(sentences):
                sentence = (sentences[i] + sentences[i + 1]).strip()
                if not sentence:
                    continue
                
                # –£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ–≤—Ç–æ—Ä—ã
                words = sentence.lower().split()
                if len(words) < 3:  # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                    result.append(sentence)
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 6 —Å–ª–æ–≤ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3
                phrase_key_start = ' '.join(words[:6])
                phrase_key_end = ' '.join(words[-3:]) if len(words) > 3 else ''
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–æ—Ö–æ–∂–µ—Å—Ç—å (–Ω–µ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
                is_repetition = False
                for seen in seen_phrases:
                    if phrase_key_start in seen or seen in phrase_key_start:
                        if len(sentence) > 30:  # –î–ª–∏–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä–æ–∂–µ
                            is_repetition = True
                            break
                
                if not is_repetition:
                    result.append(sentence)
                    seen_phrases.add(phrase_key_start)
                    if phrase_key_end:
                        seen_phrases.add(phrase_key_end)
        
        return ' '.join(result) if result else text
    
    def _adjust_emojis(self, text: str, target_density: float) -> str:
        """–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–º–æ–¥–∑–∏."""
        emojis = self.emoji_pattern.findall(text)
        current_count = len(emojis)
        target_count = int(target_density)
        
        if current_count > target_count + 1:
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —ç–º–æ–¥–∑–∏ (–æ—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–µ)
            emoji_positions = []
            for match in self.emoji_pattern.finditer(text):
                emoji_positions.append((match.start(), match.end()))
            
            # –£–¥–∞–ª—è–µ–º —ç–º–æ–¥–∑–∏, –Ω–∞—á–∏–Ω–∞—è —Å –∫–æ–Ω—Ü–∞
            for start, end in reversed(emoji_positions[target_count:]):
                text = text[:start] + text[end:]
        
        return text
    
    def _adjust_structure(self, text: str, structure_type: str) -> str:
        """–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–µ–∫—Å—Ç–∞."""
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –µ—Å—Ç—å –∞–±–∑–∞—Ü—ã
        if '\n\n' not in text and len(text) > 200:
            # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º –∏ —Å–æ–∑–¥–∞—ë–º –∞–±–∑–∞—Ü—ã
            sentences = re.split(r'([.!?]+)', text)
            paragraphs = []
            current_para = []
            
            for i in range(0, len(sentences) - 1, 2):
                if i + 1 < len(sentences):
                    sentence = (sentences[i] + sentences[i + 1]).strip()
                    current_para.append(sentence)
                    # –ö–∞–∂–¥—ã–µ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è - –Ω–æ–≤—ã–π –∞–±–∑–∞—Ü
                    if len(current_para) >= 2:
                        paragraphs.append(' '.join(current_para))
                        current_para = []
            
            if current_para:
                paragraphs.append(' '.join(current_para))
            
            if paragraphs:
                return '\n\n'.join(paragraphs)
        
        return text


class LLMInterface:
    """–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å LLM."""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-3.5-turbo"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.
        
        Args:
            api_key: API –∫–ª—é—á (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è mock)
            model: –ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        """
        self.api_key = api_key
        self.model = model
        self.use_mock = api_key is None
    
    def generate(self, prompt: str, max_tokens: int = 500) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –ø–æ –ø—Ä–æ–º–ø—Ç—É.
        
        Args:
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
            
        Returns:
            –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        if self.use_mock:
            print("‚ö†Ô∏è [LLM] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è MOCK –≥–µ–Ω–µ—Ä–∞—Ü–∏—è (API –∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)")
            return self._mock_generate(prompt)
        else:
            print(f"‚úÖ [LLM] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ–∞–ª—å–Ω—ã–π OpenAI API (–∫–ª—é—á: {self.api_key[:10]}...)")
            try:
                result = self._openai_generate(prompt, max_tokens)
                print(f"‚úÖ [LLM] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞, –¥–ª–∏–Ω–∞: {len(result)} —Å–∏–º–≤–æ–ª–æ–≤")
                return result
            except Exception as e:
                print(f"‚ùå [LLM] –û—à–∏–±–∫–∞ OpenAI API: {e}")
                print("‚ö†Ô∏è [LLM] –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ mock –≥–µ–Ω–µ—Ä–∞—Ü–∏—é")
                return self._mock_generate(prompt)
    
    def _mock_generate(self, prompt: str) -> str:
        """Mock –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è - –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–º—É –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç."""
        import re
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–º—É –∏–∑ –ø—Ä–æ–º–ø—Ç–∞ (–Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤)
        topic = None
        patterns = [
            r'–¢–ï–ú–ê –ü–û–°–¢–ê:\s*(.+?)(?:\n\n|$)',
            r'–Ω–∞ —Ç–µ–º—É\s+"(.+?)"',
            r'–Ω–∞ —Ç–µ–º—É\s+(.+?)(?:\n|$)',
            r'—Ç–µ–º–∞:\s*(.+?)(?:\n|$)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, prompt, re.IGNORECASE | re.MULTILINE)
            if match:
                topic = match.group(1).strip()
                break
        
        if not topic:
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ç–µ–º—É –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
            main_match = re.search(r'–Ω–∞ —Ç–µ–º—É\s+"?([^"]+)"?', prompt, re.IGNORECASE)
            if main_match:
                topic = main_match.group(1).strip()
        
        if not topic:
            topic = "–≤–∞–∂–Ω–æ–π —Ç–µ–º–µ"
        
        # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        topic = topic.strip('"\'')
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–∏–ª—å –∞–≤—Ç–æ—Ä–∞
        tone_match = re.search(r'–¢–æ–Ω:\s*(.+?)(?:\n|$)', prompt, re.IGNORECASE | re.MULTILINE)
        tone_text = tone_match.group(1).strip() if tone_match else ""
        is_formal = "—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π" in tone_text.lower() or "–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π" in tone_text.lower()
        is_emotional = "—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π" in tone_text.lower()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        has_lists = "—Å–ø–∏—Å–∫–∏" in prompt.lower() or "numbered_lists" in prompt.lower() or "uses_lists" in prompt.lower()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–ª–∞—Ç—Ñ–æ—Ä–º—É
        platform = "linkedin"
        if "instagram" in prompt.lower():
            platform = "instagram"
        elif "telegram" in prompt.lower():
            platform = "telegram"
        elif "facebook" in prompt.lower():
            platform = "facebook"
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–º—ã, —Å—Ç–∏–ª—è –∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
        if platform == "instagram" and is_emotional:
            return f"""–°–µ–≥–æ–¥–Ω—è —Ö–æ—á—É –ø–æ–¥–µ–ª–∏—Ç—å—Å—è –º—ã—Å–ª—è–º–∏ –æ {topic.lower()} ‚ú®

–≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –≤–∞–∂–Ω–∞—è —Ç–µ–º–∞, –∫–æ—Ç–æ—Ä–∞—è –º–µ–Ω—è –≤–¥–æ—Ö–Ω–æ–≤–ª—è–µ—Ç! üåø

–ö–æ–≥–¥–∞ —è –Ω–∞—á–∏–Ω–∞—é —Ä–∞–∑–±–∏—Ä–∞—Ç—å—Å—è –≤ –¥–µ—Ç–∞–ª—è—Ö, –æ—Ç–∫—Ä—ã–≤–∞—é—Ç—Å—è –Ω–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏. –≠—Ç–æ –Ω–µ –ø—Ä–æ –±—ã—Å—Ç—Ä—ã–µ —Ä–µ—à–µ–Ω–∏—è, –∞ –ø—Ä–æ –≥–ª—É–±–æ–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ.

–ß—Ç–æ –≤—ã –¥—É–º–∞–µ—Ç–µ –æ–± —ç—Ç–æ–º? üí≠"""
        
        elif platform == "telegram":
            return f"""‚ö°Ô∏è –ë—ã—Å—Ç—Ä—ã–µ –º—ã—Å–ª–∏ –æ {topic.lower()}

–ß–µ—Å—Ç–Ω–æ –≥–æ–≤–æ—Ä—è, —è –¥—É–º–∞—é, —á—Ç–æ –º–Ω–æ–≥–∏–µ –ª—é–¥–∏ –ø–æ–¥—Ö–æ–¥—è—Ç –∫ —ç—Ç–æ–º—É –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ. {topic} ‚Äî —ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ –∫–æ–Ω—Ü–µ–ø—Ü–∏—è, –∞ —Ä–µ–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç.

–ö–æ–≥–¥–∞ –º—ã –Ω–∞—á–∏–Ω–∞–µ–º –ø—Ä–∏–º–µ–Ω—è—Ç—å —ç—Ç–æ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ, –æ—Ç–∫—Ä—ã–≤–∞—é—Ç—Å—è –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏. –í–∞–∂–Ω–æ –Ω–µ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å—Å—è –Ω–∞ —Ç–µ–æ—Ä–∏–∏.

–ß—Ç–æ –≤—ã –æ–± —ç—Ç–æ–º –¥—É–º–∞–µ—Ç–µ?"""
        
        elif has_lists:
            return f"""–°–µ–≥–æ–¥–Ω—è —Ö–æ—á—É –ø–æ–¥–µ–ª–∏—Ç—å—Å—è –º—ã—Å–ª—è–º–∏ –æ {topic.lower()}.

–ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –≥–æ–¥—ã —è –ø–æ–Ω—è–ª, —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –≤–∞–∂–Ω–∞—è —Ç–µ–º–∞, –∫–æ—Ç–æ—Ä–∞—è —Ç—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è –∏ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞.

–ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã:

1. –ü–µ—Ä–≤—ã–π –≤–∞–∂–Ω—ã–π –∞—Å–ø–µ–∫—Ç —Å–≤—è–∑–∞–Ω —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –æ—Å–Ω–æ–≤ –∏ –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤
2. –í—Ç–æ—Ä–æ–π –º–æ–º–µ–Ω—Ç ‚Äî —ç—Ç–æ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö
3. –¢—Ä–µ—Ç–∏–π —ç–ª–µ–º–µ–Ω—Ç ‚Äî –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ –∏ —É–ª—É—á—à–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–∞

{topic} ‚Äî —ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ –∫–æ–Ω—Ü–µ–ø—Ü–∏—è, –∞ —Ä–µ–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–π. –í–∞–∂–Ω–æ –ø—Ä–∏–º–µ–Ω—è—Ç—å —ç—Ç–æ —Å–∏—Å—Ç–µ–º–Ω–æ."""
        
        else:
            intro = "–°–µ–≥–æ–¥–Ω—è —Ö–æ—á—É –ø–æ–¥–µ–ª–∏—Ç—å—Å—è –º—ã—Å–ª—è–º–∏" if is_formal else "–•–æ—á—É –ø–æ–¥–µ–ª–∏—Ç—å—Å—è –º—ã—Å–ª—è–º–∏"
            return f"""{intro} –æ {topic.lower()}.

–ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –≥–æ–¥—ã —è –ø–æ–Ω—è–ª, —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –≤–∞–∂–Ω–∞—è —Ç–µ–º–∞. –ö–æ–≥–¥–∞ –º—ã –Ω–∞—á–∏–Ω–∞–µ–º —Ä–∞–∑–±–∏—Ä–∞—Ç—å—Å—è –≤ –¥–µ—Ç–∞–ª—è—Ö, –æ—Ç–∫—Ä—ã–≤–∞—é—Ç—Å—è –Ω–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã.

–í–∞–∂–Ω–æ –ø–æ–Ω–∏–º–∞—Ç—å, —á—Ç–æ {topic.lower()} —Ç—Ä–µ–±—É–µ—Ç —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞. –≠—Ç–æ –Ω–µ –ø—Ä–æ –±—ã—Å—Ç—Ä—ã–µ —Ä–µ—à–µ–Ω–∏—è, –∞ –ø—Ä–æ –≥–ª—É–±–æ–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∏ –º–µ—Ö–∞–Ω–∏–∑–º–æ–≤.

–ß—Ç–æ –≤—ã –¥—É–º–∞–µ—Ç–µ –æ–± —ç—Ç–æ–º?"""
    
    def _openai_generate(self, prompt: str, max_tokens: int) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ OpenAI API."""
        try:
            from openai import OpenAI
            
            client = OpenAI(api_key=self.api_key)
            response = client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
        except ImportError:
            print("‚ö†Ô∏è  OpenAI –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è mock")
            return self._mock_generate(prompt)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è mock")
            return self._mock_generate(prompt)


class GhostPenGenerator:
    """–û—Å–Ω–æ–≤–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø–æ—Å—Ç–æ–≤ GhostPen."""
    
    def __init__(
        self,
        profiles_path: Path,
        llm_api_key: Optional[str] = None,
        llm_model: str = "gpt-3.5-turbo"
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞.
        
        Args:
            profiles_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –ø—Ä–æ—Ñ–∏–ª—è–º–∏
            llm_api_key: API –∫–ª—é—á –¥–ª—è LLM (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            llm_model: –ú–æ–¥–µ–ª—å LLM
        """
        self.prompt_builder = PromptBuilder(profiles_path)
        self.llm = LLMInterface(llm_api_key, llm_model)
        self.processor = PostProcessor()
    
    def generate_post(
        self,
        author_id: str,
        platform: str,
        topic: str,
        additional_context: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ—Å—Ç –≤ —Å—Ç–∏–ª–µ –∞–≤—Ç–æ—Ä–∞.
        
        Args:
            author_id: ID –∞–≤—Ç–æ—Ä–∞
            platform: –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞
            topic: –¢–µ–º–∞ –ø–æ—Å—Ç–∞
            additional_context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        """
        # 1. –°—Ç—Ä–æ–∏–º –ø—Ä–æ–º–ø—Ç
        prompt = self.prompt_builder.build_prompt(
            author_id, platform, topic, additional_context
        )
        
        # 2. –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        profile = self.prompt_builder.profiles[author_id]
        style = profile.get('style', {})
        platform_style = profile.get('platform_specific', {}).get(platform, {})
        
        target_length = platform_style.get('avg_length', style.get('avg_post_length', 300))
        emoji_density = platform_style.get('emoji_density', style.get('emoji_density', 0))
        hashtag_density = platform_style.get('hashtag_density', style.get('hashtag_density', 0))
        structure_type = style.get('structure_type', 'paragraphs')
        
        # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ LLM
        raw_text = self.llm.generate(prompt, max_tokens=500)
        
        # 4. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        processed_text = self.processor.process(
            raw_text,
            target_length,
            emoji_density,
            hashtag_density,
            structure_type
        )
        
        return {
            "author_id": author_id,
            "platform": platform,
            "topic": topic,
            "generated_post": processed_text,
            "raw_post": raw_text,
            "prompt_used": prompt,
            "metrics": {
                "length": len(processed_text),
                "target_length": target_length,
                "length_match": abs(len(processed_text) - target_length) / target_length < 0.3
            }
        }


def main():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞."""
    import sys
    
    if len(sys.argv) < 4:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python ghostpen_generator.py <profiles.json> <author_id> <platform> <topic> [api_key]")
        print("\n–ü—Ä–∏–º–µ—Ä:")
        print("  python ghostpen_generator.py dataset/author_profiles.json person_01 linkedin '–û –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è'")
        sys.exit(1)
    
    profiles_path = Path(sys.argv[1])
    author_id = sys.argv[2]
    platform = sys.argv[3]
    topic = sys.argv[4] if len(sys.argv) > 4 else "–û –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è"
    api_key = sys.argv[5] if len(sys.argv) > 5 else None
    
    generator = GhostPenGenerator(profiles_path, api_key)
    
    try:
        result = generator.generate_post(author_id, platform, topic)
        
        print("=" * 80)
        print("–°–ì–ï–ù–ï–†–ò–†–û–í–ê–ù–ù–´–ô –ü–û–°–¢:")
        print("=" * 80)
        print(result["generated_post"])
        print("=" * 80)
        print(f"\n–î–ª–∏–Ω–∞: {result['metrics']['length']} —Å–∏–º–≤–æ–ª–æ–≤ (—Ü–µ–ª—å: {result['metrics']['target_length']})")
        print(f"–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–ª–∏–Ω–µ: {'‚úì' if result['metrics']['length_match'] else '‚úó'}")
    except ValueError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()

