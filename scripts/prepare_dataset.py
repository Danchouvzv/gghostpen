#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ GhostPen.
"""

import json
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any
import jsonschema


def validate_dataset(dataset_path: Path, schema_path: Path) -> bool:
    """
    –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –ø–æ JSON Schema.
    
    Args:
        dataset_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–∞—Ç–∞—Å–µ—Ç–∞
        schema_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å—Ö–µ–º—ã
        
    Returns:
        True –µ—Å–ª–∏ –≤–∞–ª–∏–¥–µ–Ω, False –∏–Ω–∞—á–µ
    """
    try:
        with open(dataset_path, 'r', encoding='utf-8') as f:
            dataset = json.load(f)
        
        with open(schema_path, 'r', encoding='utf-8') as f:
            schema = json.load(f)
        
        jsonschema.validate(instance=dataset, schema=schema)
        print("‚úÖ –î–∞—Ç–∞—Å–µ—Ç –≤–∞–ª–∏–¥–µ–Ω!")
        return True
    except jsonschema.ValidationError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e.message}")
        print(f"   –ü—É—Ç—å: {'.'.join(str(x) for x in e.path)}")
        return False
    except json.JSONDecodeError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
        return False
    except FileNotFoundError as e:
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")
        return False


def get_dataset_stats(dataset_path: Path) -> Dict[str, Any]:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É.
    
    Args:
        dataset_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–∞—Ç–∞—Å–µ—Ç–∞
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
    """
    with open(dataset_path, 'r', encoding='utf-8') as f:
        dataset = json.load(f)
    
    stats = {
        "total_authors": len(dataset["authors"]),
        "total_posts": 0,
        "platforms": {
            "linkedin": 0,
            "instagram": 0,
            "facebook": 0,
            "telegram": 0
        },
        "avg_post_length": 0,
        "authors_details": []
    }
    
    total_length = 0
    
    for author in dataset["authors"]:
        author_stats = {
            "author_id": author["author_id"],
            "total_posts": 0,
            "platforms": {}
        }
        
        for platform, posts in author["platforms"].items():
            count = len(posts)
            stats["platforms"][platform] += count
            stats["total_posts"] += count
            author_stats["total_posts"] += count
            author_stats["platforms"][platform] = count
            
            for post in posts:
                total_length += len(post["content"])
        
        stats["authors_details"].append(author_stats)
    
    if stats["total_posts"] > 0:
        stats["avg_post_length"] = total_length // stats["total_posts"]
    
    return stats


def print_stats(stats: Dict[str, Any]) -> None:
    """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ –∫–æ–Ω—Å–æ–ª—å."""
    print("\n" + "="*50)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –î–ê–¢–ê–°–ï–¢–ê")
    print("="*50)
    print(f"–ê–≤—Ç–æ—Ä–æ–≤: {stats['total_authors']}")
    print(f"–í—Å–µ–≥–æ –ø–æ—Å—Ç–æ–≤: {stats['total_posts']}")
    print(f"\n–ü–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º:")
    for platform, count in stats['platforms'].items():
        if count > 0:
            print(f"  {platform}: {count}")
    print(f"\n–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø–æ—Å—Ç–∞: {stats['avg_post_length']} —Å–∏–º–≤–æ–ª–æ–≤")
    print("\n–ü–æ –∞–≤—Ç–æ—Ä–∞–º:")
    for author in stats['authors_details']:
        print(f"  {author['author_id']}: {author['total_posts']} –ø–æ—Å—Ç–æ–≤")
        for platform, count in author['platforms'].items():
            if count > 0:
                print(f"    - {platform}: {count}")
    print("="*50 + "\n")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python prepare_dataset.py <–∫–æ–º–∞–Ω–¥–∞> [–∞—Ä–≥—É–º–µ–Ω—Ç—ã]")
        print("\n–ö–æ–º–∞–Ω–¥—ã:")
        print("  validate <dataset.json> <schema.json>  - –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞")
        print("  stats <dataset.json>                   - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞")
        sys.exit(1)
    
    command = sys.argv[1]
    
    if command == "validate":
        if len(sys.argv) < 4:
            print("–û—à–∏–±–∫–∞: —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç–∏ –∫ –¥–∞—Ç–∞—Å–µ—Ç—É –∏ —Å—Ö–µ–º–µ")
            sys.exit(1)
        
        dataset_path = Path(sys.argv[2])
        schema_path = Path(sys.argv[3])
        
        if not validate_dataset(dataset_path, schema_path):
            sys.exit(1)
    
    elif command == "stats":
        if len(sys.argv) < 3:
            print("–û—à–∏–±–∫–∞: —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É")
            sys.exit(1)
        
        dataset_path = Path(sys.argv[2])
        stats = get_dataset_stats(dataset_path)
        print_stats(stats)
    
    else:
        print(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞: {command}")
        sys.exit(1)


if __name__ == "__main__":
    main()

